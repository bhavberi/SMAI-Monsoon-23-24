{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../Datasets/WineQT.csv\"\n",
    "\n",
    "random_state = 42\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "hyperparameter_tuning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "max_epochs = 10000\n",
    "optimizer = 'bgd'\n",
    "activation = 'sigmoid'\n",
    "hidden_layers = [8,]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_init(lr, max_epochs, optimizer, activation, hidden_layers, batch_size):\n",
    "    config = {\n",
    "        \"lr\": lr, \n",
    "        \"model_type\": \"MLP_Classifier\",\n",
    "        \"optimizer\": optimizer, # SGC/BGD/MBGD\n",
    "        \"criterion\": \"mse\",\n",
    "        \"num_epochs\": max_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"hidden_layers\": hidden_layers,\n",
    "        \"activation\": activation,\n",
    "        # \"gpu_id\": 0,\n",
    "        \"wandb_run_name\": \"bhav\" ,\n",
    "        \"tags\": [\"P2\",]\n",
    "    }\n",
    "\n",
    "    wandb.init(entity = \"bhavberi\",   # wandb username. (NOT REQUIRED ARG. ANYMORE, it fetches from initial login)\n",
    "            project = \"SMAI\",        # wandb project name. New project will be created if given project is missing.\n",
    "            config = config         # Config dict\n",
    "            )\n",
    "    wandb.run.name = f\"P2_{config['optimizer']}_{config['activation']}_{len(config['hidden_layers'])}_{config['lr']}_{config['batch_size']}_{config['num_epochs']}\"\n",
    "    print(wandb.run.name)\n",
    "\n",
    "def wandb_finish():\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality', 'Id'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(dataset_path)\n",
    "print(dataset.columns)\n",
    "dataset.drop(['Id'], axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.311111</td>\n",
       "      <td>0.531339</td>\n",
       "      <td>0.268364</td>\n",
       "      <td>2.532152</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>15.615486</td>\n",
       "      <td>45.914698</td>\n",
       "      <td>0.996730</td>\n",
       "      <td>3.311015</td>\n",
       "      <td>0.657708</td>\n",
       "      <td>10.442111</td>\n",
       "      <td>5.657043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.747595</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.196686</td>\n",
       "      <td>1.355917</td>\n",
       "      <td>0.047267</td>\n",
       "      <td>10.250486</td>\n",
       "      <td>32.782130</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.156664</td>\n",
       "      <td>0.170399</td>\n",
       "      <td>1.082196</td>\n",
       "      <td>0.805824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.995570</td>\n",
       "      <td>3.205000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.996680</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.997845</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1143.000000       1143.000000  1143.000000     1143.000000   \n",
       "mean        8.311111          0.531339     0.268364        2.532152   \n",
       "std         1.747595          0.179633     0.196686        1.355917   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.392500     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.250000        2.200000   \n",
       "75%         9.100000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1143.000000          1143.000000           1143.000000  1143.000000   \n",
       "mean      0.086933            15.615486             45.914698     0.996730   \n",
       "std       0.047267            10.250486             32.782130     0.001925   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             21.000000     0.995570   \n",
       "50%       0.079000            13.000000             37.000000     0.996680   \n",
       "75%       0.090000            21.000000             61.000000     0.997845   \n",
       "max       0.611000            68.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1143.000000  1143.000000  1143.000000  1143.000000  \n",
       "mean      3.311015     0.657708    10.442111     5.657043  \n",
       "std       0.156664     0.170399     1.082196     0.805824  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.205000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['quality']).to_numpy()\n",
    "y = dataset['quality'].to_numpy()\n",
    "\n",
    "num_classes = 11 # 0-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "# To fill in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (914, 11) (914,)\n",
      "Validation set shape: (114, 11) (114,)\n",
      "Test set shape: (115, 11) (115,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_state)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_validation.shape, y_validation.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_validation_std = scaler.transform(X_validation)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Classifier:\n",
    "    def __init__(self, input_size, hidden_layers, num_classes=11, learning_rate=0.01, activation='sigmoid', optimizer='sgd', wandb_log=False, print_every=10):\n",
    "        assert activation.lower() in ['sigmoid', 'relu', 'tanh'], \"Activation function must be either 'sigmoid', 'relu' or 'tanh'\"\n",
    "        assert optimizer.lower() in ['sgd', 'bgd', 'mbgd'], \"Optimizer must be either 'sgd', 'bgd' or 'mbgd'\"\n",
    "        assert input_size > 0, \"Input size must be greater than 0\"\n",
    "        assert num_classes > 0, \"Output size must be greater than 0\"\n",
    "        assert learning_rate > 0, \"Learning rate must be greater than 0\"\n",
    "        assert type(hidden_layers) == list and len(hidden_layers) > 0, \"Hidden layers must be a list of size greater than 0\"\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        self.activation_func = self._get_activation_func(activation)\n",
    "        self.optimizer_func = self._get_optimizer_func(optimizer)\n",
    "        self.weights, self.biases = self._initialize_weights_and_biases()\n",
    "\n",
    "        self.wandb_log = wandb_log\n",
    "        self.print_every = print_every\n",
    "    \n",
    "    # Activation functions\n",
    "    def _get_activation_func(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            return self._sigmoid\n",
    "        elif activation == 'tanh':\n",
    "            return self._tanh\n",
    "        elif activation == 'relu':\n",
    "            return self._relu\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function '{activation}' not supported.\")\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    # Activation derivative\n",
    "    def _activation_derivative(self, Z):\n",
    "        if self.activation_func == self._sigmoid:\n",
    "            return self._sigmoid_derivative(Z)\n",
    "        elif self.activation_func == self._tanh:\n",
    "            return self._tanh_derivative(Z)\n",
    "        elif self.activation_func == self._relu:\n",
    "            return self._relu_derivative(Z)\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function '{self.activation_func}' not supported.\")\n",
    "    \n",
    "    def _sigmoid_derivative(self, Z):\n",
    "        return self._sigmoid(Z) * (1 - self._sigmoid(Z))\n",
    "    \n",
    "    def _tanh_derivative(self, Z):\n",
    "        return 1 - np.square(self._tanh(Z))\n",
    "    \n",
    "    def _relu_derivative(self, Z):\n",
    "        return np.where(Z > 0, 1, 0)\n",
    "    \n",
    "    ## Optimizers\n",
    "    def _get_optimizer_func(self, optimizer):\n",
    "        if optimizer == 'sgd':\n",
    "            return self._sgd\n",
    "        elif optimizer == 'bgd':\n",
    "            return self._bgd\n",
    "        elif optimizer == 'mbgd':\n",
    "            return self._mbgd\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer '{optimizer}' not supported.\")\n",
    "    \n",
    "    def _sgd(self, grads):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= (self.learning_rate * grads['dW'][i])\n",
    "            self.biases[i] -= (self.learning_rate * grads['db'][i])\n",
    "    \n",
    "    def _bgd(self, grads):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= (self.learning_rate * grads['dW'][i] / self.input_size)\n",
    "            self.biases[i] -= (self.learning_rate * grads['db'][i] / self.input_size)\n",
    "\n",
    "    def _mbgd(self, grads):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= (self.learning_rate * grads['dW'][i] / grads['dW'][i].shape[1])\n",
    "            self.biases[i] -= (self.learning_rate * grads['db'][i] / grads['db'][i].shape[1])\n",
    "    \n",
    "    # Initialize weights and biases\n",
    "    def _initialize_weights_and_biases(self):\n",
    "        num_layers = len(self.hidden_layers)\n",
    "        weights = []\n",
    "        biases = []\n",
    "\n",
    "        if num_layers == 0:\n",
    "            w = np.random.randn(self.input_size, self.output_size)\n",
    "            b = np.zeros((1, self.output_size))\n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "            return weights, biases\n",
    "        \n",
    "        # Using Github Copilot\n",
    "        for i in range(num_layers + 1):\n",
    "            if i == 0:\n",
    "                w = np.random.randn(self.input_size, self.hidden_layers[0])\n",
    "            elif i == num_layers:\n",
    "                w = np.random.randn(self.hidden_layers[-1], self.output_size)\n",
    "            else:\n",
    "                w = np.random.randn(self.hidden_layers[i - 1], self.hidden_layers[i])\n",
    "            \n",
    "            b = np.zeros((1, w.shape[1]))\n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "    \n",
    "    # Forward propagation\n",
    "    def _forward_propagation(self, X):\n",
    "        num_layers = len(self.weights)\n",
    "        A = X\n",
    "        caches = []\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            W = self.weights[i]\n",
    "            b = self.biases[i]\n",
    "            Z = np.dot(A, W) + b\n",
    "            \n",
    "            if Z.shape[1] == 1:\n",
    "                Z = Z.reshape(-1)\n",
    "            caches.append((A, W, b, Z))\n",
    "            # print(A.shape, W.shape, b.shape, Z.shape)\n",
    "\n",
    "            A = self.activation_func(Z)\n",
    "        \n",
    "        if len(A.shape) == 1:\n",
    "            A = A.reshape(-1)\n",
    "        return A, caches\n",
    "\n",
    "    # Backward propagation\n",
    "    def _backward_propagation(self, A, Y, caches):\n",
    "        num_samples = A.shape[0]\n",
    "        num_layers = len(self.weights)\n",
    "        grads = {'dW': [], 'db': []}\n",
    "\n",
    "        delta = A-Y\n",
    "        # print(delta.shape, A.shape, Y.shape)\n",
    "\n",
    "        for i in reversed(range(num_layers)):\n",
    "            A, W, _, Z = caches[i]\n",
    "            # print(\"A\", A.shape, \"W\", W.shape, \"Z\", Z.shape)\n",
    "            \n",
    "            dZ = np.multiply(delta, self._activation_derivative(Z))\n",
    "            if dZ.ndim == 1:\n",
    "                dZ = dZ.reshape((dZ.shape[0], 1))\n",
    "            # print(\"dZ\", dZ.shape)\n",
    "            dW = np.dot(A.T, dZ)\n",
    "            # print(\"dW\", dW.shape)\n",
    "            db = np.sum(dZ, axis=0, keepdims=True)\n",
    "            # print(\"db\", db.shape)\n",
    "\n",
    "            delta = np.dot(dZ, W.T)\n",
    "            # print(\"delta\", delta.shape)\n",
    "\n",
    "            if len(dW.shape) == 1:\n",
    "                dW = dW.reshape(-1, 1)\n",
    "\n",
    "            grads['dW'].append(dW)\n",
    "            grads['db'].append(db)\n",
    "        \n",
    "        grads['dW'].reverse()\n",
    "        grads['db'].reverse()\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    # Calculate cost\n",
    "    def _calculate_cost(self, A, Y):\n",
    "        cost = np.mean(np.not_equal(A, Y))\n",
    "        return cost\n",
    "\n",
    "    # Predict\n",
    "    def predict(self, X):\n",
    "        A, _ = self._forward_propagation(X)\n",
    "\n",
    "        # Apply a softmax to get probabilities & then getting the h9ghest probability\n",
    "        A = np.exp(A) / np.sum(np.exp(A), axis=1, keepdims=True)\n",
    "\n",
    "        A = np.argmax(A,axis=1)\n",
    "        return A\n",
    "\n",
    "    # Train the model\n",
    "    def train(self, X, Y, max_epochs=10, batch_size=32, X_validation=None, y_validation=None):\n",
    "        num_samples = X.shape[0]\n",
    "        costs = []\n",
    "\n",
    "        enc = OneHotEncoder().fit(np.array([[i,] for i in range(num_classes)]))\n",
    "        y_new = enc.transform(Y.reshape(-1, 1)).toarray()\n",
    "        \n",
    "        for i in range(max_epochs):\n",
    "            if self.optimizer == \"bgd\":\n",
    "                batch_size = num_samples\n",
    "                num_batches = 1\n",
    "            elif self.optimizer == \"sgd\":\n",
    "                batch_size = 1\n",
    "                num_batches = num_samples\n",
    "            elif self.optimizer == \"mbgd\":\n",
    "                num_batches = num_samples // batch_size\n",
    "            else:\n",
    "                raise ValueError(f\"Optimizer '{self.optimizer}' not supported.\")\n",
    "\n",
    "            for j in range(num_batches):\n",
    "                start = j * batch_size\n",
    "                end = start + batch_size\n",
    "                \n",
    "                A, caches = self._forward_propagation(X[start:end])\n",
    "                grads = self._backward_propagation(A, y_new[start:end], caches)\n",
    "                self.optimizer_func(grads)\n",
    "            \n",
    "            A = self.predict(X)\n",
    "            cost = self._calculate_cost(A, Y)\n",
    "            costs.append(cost)\n",
    "\n",
    "            data_to_log = {\n",
    "                \"epoch\": i + 1,\n",
    "                \"train_loss\": cost\n",
    "            }\n",
    "\n",
    "            # Calculate validation loss\n",
    "            if X_validation is not None and y_validation is not None:\n",
    "                A = self.predict(X_validation)\n",
    "                val_loss = self._calculate_cost(A, y_validation)\n",
    "                data_to_log[\"val_loss\"] = val_loss\n",
    "\n",
    "            if self.wandb_log:\n",
    "                wandb.log(data_to_log)\n",
    "            \n",
    "            if self.print_every and (i+1) % self.print_every == 0:\n",
    "                print(f\"Cost after {i+1} epochs: {cost}\")\n",
    "        \n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 100 epochs: 0.8140043763676149\n",
      "Cost after 200 epochs: 0.6575492341356673\n",
      "Cost after 300 epochs: 0.6148796498905909\n",
      "Cost after 400 epochs: 0.6214442013129103\n",
      "Cost after 500 epochs: 0.600656455142232\n",
      "Cost after 600 epochs: 0.5886214442013129\n",
      "Cost after 700 epochs: 0.5601750547045952\n",
      "Cost after 800 epochs: 0.5361050328227571\n",
      "Cost after 900 epochs: 0.5229759299781181\n",
      "Cost after 1000 epochs: 0.5054704595185996\n",
      "Cost after 1100 epochs: 0.48577680525164113\n",
      "Cost after 1200 epochs: 0.48468271334792123\n",
      "Cost after 1300 epochs: 0.47045951859956237\n",
      "Cost after 1400 epochs: 0.4660831509846827\n",
      "Cost after 1500 epochs: 0.4617067833698031\n",
      "Cost after 1600 epochs: 0.45185995623632386\n",
      "Cost after 1700 epochs: 0.44638949671772427\n",
      "Cost after 1800 epochs: 0.4420131291028446\n",
      "Cost after 1900 epochs: 0.4365426695842451\n",
      "Cost after 2000 epochs: 0.43216630196936545\n",
      "Cost after 2100 epochs: 0.42778993435448576\n",
      "Cost after 2200 epochs: 0.4223194748358862\n",
      "Cost after 2300 epochs: 0.4179431072210066\n",
      "Cost after 2400 epochs: 0.4135667396061269\n",
      "Cost after 2500 epochs: 0.4113785557986871\n",
      "Cost after 2600 epochs: 0.4102844638949672\n",
      "Cost after 2700 epochs: 0.4113785557986871\n",
      "Cost after 2800 epochs: 0.4113785557986871\n",
      "Cost after 2900 epochs: 0.41466083150984684\n",
      "Cost after 3000 epochs: 0.41466083150984684\n",
      "Cost after 3100 epochs: 0.4135667396061269\n",
      "Cost after 3200 epochs: 0.4113785557986871\n",
      "Cost after 3300 epochs: 0.40919037199124725\n",
      "Cost after 3400 epochs: 0.40700218818380746\n",
      "Cost after 3500 epochs: 0.40919037199124725\n",
      "Cost after 3600 epochs: 0.40919037199124725\n",
      "Cost after 3700 epochs: 0.40809628008752735\n",
      "Cost after 3800 epochs: 0.40809628008752735\n",
      "Cost after 3900 epochs: 0.4059080962800875\n",
      "Cost after 4000 epochs: 0.4059080962800875\n",
      "Cost after 4100 epochs: 0.4048140043763676\n",
      "Cost after 4200 epochs: 0.4048140043763676\n",
      "Cost after 4300 epochs: 0.4037199124726477\n",
      "Cost after 4400 epochs: 0.4026258205689278\n",
      "Cost after 4500 epochs: 0.4037199124726477\n",
      "Cost after 4600 epochs: 0.40809628008752735\n",
      "Cost after 4700 epochs: 0.40809628008752735\n",
      "Cost after 4800 epochs: 0.4059080962800875\n",
      "Cost after 4900 epochs: 0.4059080962800875\n",
      "Cost after 5000 epochs: 0.4048140043763676\n",
      "Cost after 5100 epochs: 0.4048140043763676\n",
      "Cost after 5200 epochs: 0.4037199124726477\n",
      "Cost after 5300 epochs: 0.4037199124726477\n",
      "Cost after 5400 epochs: 0.40153172866520787\n",
      "Cost after 5500 epochs: 0.40043763676148797\n",
      "Cost after 5600 epochs: 0.3993435448577681\n",
      "Cost after 5700 epochs: 0.3993435448577681\n",
      "Cost after 5800 epochs: 0.40043763676148797\n",
      "Cost after 5900 epochs: 0.40043763676148797\n",
      "Cost after 6000 epochs: 0.3982494529540481\n",
      "Cost after 6100 epochs: 0.3982494529540481\n",
      "Cost after 6200 epochs: 0.3982494529540481\n",
      "Cost after 6300 epochs: 0.3982494529540481\n",
      "Cost after 6400 epochs: 0.3971553610503282\n",
      "Cost after 6500 epochs: 0.3971553610503282\n",
      "Cost after 6600 epochs: 0.3993435448577681\n",
      "Cost after 6700 epochs: 0.3993435448577681\n",
      "Cost after 6800 epochs: 0.3993435448577681\n",
      "Cost after 6900 epochs: 0.3993435448577681\n",
      "Cost after 7000 epochs: 0.40043763676148797\n",
      "Cost after 7100 epochs: 0.40043763676148797\n",
      "Cost after 7200 epochs: 0.40043763676148797\n",
      "Cost after 7300 epochs: 0.40043763676148797\n",
      "Cost after 7400 epochs: 0.40043763676148797\n",
      "Cost after 7500 epochs: 0.40043763676148797\n",
      "Cost after 7600 epochs: 0.40043763676148797\n",
      "Cost after 7700 epochs: 0.3982494529540481\n",
      "Cost after 7800 epochs: 0.3982494529540481\n",
      "Cost after 7900 epochs: 0.3982494529540481\n",
      "Cost after 8000 epochs: 0.3982494529540481\n",
      "Cost after 8100 epochs: 0.3982494529540481\n",
      "Cost after 8200 epochs: 0.3982494529540481\n",
      "Cost after 8300 epochs: 0.3982494529540481\n",
      "Cost after 8400 epochs: 0.3993435448577681\n",
      "Cost after 8500 epochs: 0.3993435448577681\n",
      "Cost after 8600 epochs: 0.3993435448577681\n",
      "Cost after 8700 epochs: 0.3993435448577681\n",
      "Cost after 8800 epochs: 0.3993435448577681\n",
      "Cost after 8900 epochs: 0.3993435448577681\n",
      "Cost after 9000 epochs: 0.3993435448577681\n",
      "Cost after 9100 epochs: 0.40043763676148797\n",
      "Cost after 9200 epochs: 0.40153172866520787\n",
      "Cost after 9300 epochs: 0.3993435448577681\n",
      "Cost after 9400 epochs: 0.40043763676148797\n",
      "Cost after 9500 epochs: 0.40043763676148797\n",
      "Cost after 9600 epochs: 0.40043763676148797\n",
      "Cost after 9700 epochs: 0.40043763676148797\n",
      "Cost after 9800 epochs: 0.40043763676148797\n",
      "Cost after 9900 epochs: 0.3982494529540481\n",
      "Cost after 10000 epochs: 0.3982494529540481\n"
     ]
    }
   ],
   "source": [
    "model = MLP_Classifier(X_train_std.shape[1], hidden_layers, num_classes, learning_rate=lr, activation=activation, optimizer=optimizer, print_every=100)\n",
    "costs = model.train(X_train_std, y_train, max_epochs=max_epochs, batch_size=batch_size, X_validation=X_validation_std, y_validation=y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(costs)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.67      0.78      0.72        50\n",
      "           6       0.50      0.64      0.56        44\n",
      "           7       1.00      0.06      0.12        16\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.59       115\n",
      "   macro avg       0.43      0.30      0.28       115\n",
      "weighted avg       0.62      0.59      0.54       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test_std), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparameter_tuning:\n",
    "    for optimizer in ['sgd', 'bgd', 'mbgd']:\n",
    "        for activation in ['sigmoid', 'relu', 'tanh']:\n",
    "            for lr in [0.001, 0.01, 0.1]:\n",
    "                max_epochs = 1000\n",
    "                if optimizer == 'mbgd':\n",
    "                    batch_sizes = [32, 64]\n",
    "                else:\n",
    "                    batch_sizes = [32,]\n",
    "                for batch_size in batch_sizes:\n",
    "                    wandb_init(lr, max_epochs, optimizer, activation, hidden_layers, batch_size)\n",
    "                    model = MLP_Classifier(X_train_std.shape[1], hidden_layers, num_classes, learning_rate=lr, activation=activation, optimizer=optimizer, print_every=None, wandb_log=True)\n",
    "                    costs = model.train(X_train_std, y_train, max_epochs=max_epochs, batch_size=batch_size, X_validation=X_validation_std, y_validation=y_validation)\n",
    "                    accuracy = accuracy_score(y_test, model.predict(X_test_std))\n",
    "                    precision = precision_score(y_test, model.predict(X_test_std), average='macro', zero_division=1)\n",
    "                    recall = recall_score(y_test, model.predict(X_test_std), average='macro', zero_division=1)\n",
    "                    f1 = f1_score(y_test, model.predict(X_test_std), average='macro', zero_division=1)\n",
    "                    wandb.log({\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"precision\": precision,\n",
    "                        \"recall\": recall,\n",
    "                        \"f1\": f1\n",
    "                    })\n",
    "                    wandb_finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2_sgd_sigmoid_1_0.01_32_1000</td>\n",
       "      <td>119</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.678261</td>\n",
       "      <td>0.411827</td>\n",
       "      <td>0.829489</td>\n",
       "      <td>0.405955</td>\n",
       "      <td>0.287746</td>\n",
       "      <td>0.385965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2_sgd_tanh_1_0.001_32_1000</td>\n",
       "      <td>76</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.678261</td>\n",
       "      <td>0.389418</td>\n",
       "      <td>0.799258</td>\n",
       "      <td>0.388409</td>\n",
       "      <td>0.377462</td>\n",
       "      <td>0.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2_mbgd_sigmoid_1_0.01_64_1000</td>\n",
       "      <td>18</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>mbgd</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.390603</td>\n",
       "      <td>0.818413</td>\n",
       "      <td>0.383864</td>\n",
       "      <td>0.376368</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P2_bgd_sigmoid_1_0.01_32_1000</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>0.010</td>\n",
       "      <td>bgd</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.391308</td>\n",
       "      <td>0.795139</td>\n",
       "      <td>0.391227</td>\n",
       "      <td>0.385120</td>\n",
       "      <td>0.377193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P2_mbgd_sigmoid_1_0.1_64_1000</td>\n",
       "      <td>18</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>0.100</td>\n",
       "      <td>mbgd</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.383345</td>\n",
       "      <td>0.786462</td>\n",
       "      <td>0.384364</td>\n",
       "      <td>0.318381</td>\n",
       "      <td>0.385965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  Runtime activation  batch_size     lr  \\\n",
       "0   P2_sgd_sigmoid_1_0.01_32_1000      119    sigmoid          32  0.010   \n",
       "1     P2_sgd_tanh_1_0.001_32_1000       76       tanh          32  0.001   \n",
       "2  P2_mbgd_sigmoid_1_0.01_64_1000       18    sigmoid          64  0.010   \n",
       "3   P2_bgd_sigmoid_1_0.01_32_1000       16    sigmoid          32  0.010   \n",
       "4   P2_mbgd_sigmoid_1_0.1_64_1000       18    sigmoid          64  0.100   \n",
       "\n",
       "  optimizer  accuracy        f1  precision    recall  train_loss  val_loss  \n",
       "0       sgd  0.678261  0.411827   0.829489  0.405955    0.287746  0.385965  \n",
       "1       sgd  0.678261  0.389418   0.799258  0.388409    0.377462  0.403509  \n",
       "2      mbgd  0.669565  0.390603   0.818413  0.383864    0.376368  0.447368  \n",
       "3       bgd  0.652174  0.391308   0.795139  0.391227    0.385120  0.377193  \n",
       "4      mbgd  0.652174  0.383345   0.786462  0.384364    0.318381  0.385965  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import from csv file ../wandb_export_P2.csv\n",
    "\n",
    "wandb_data = pd.read_csv(\"../wandb_export_P2.csv\")\n",
    "wandb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Name  accuracy        f1  precision    recall\n",
      "0     P2_sgd_sigmoid_1_0.01_32_1000  0.678261  0.411827   0.829489  0.405955\n",
      "1       P2_sgd_tanh_1_0.001_32_1000  0.678261  0.389418   0.799258  0.388409\n",
      "2    P2_mbgd_sigmoid_1_0.01_64_1000  0.669565  0.390603   0.818413  0.383864\n",
      "3     P2_bgd_sigmoid_1_0.01_32_1000  0.652174  0.391308   0.795139  0.391227\n",
      "4     P2_mbgd_sigmoid_1_0.1_64_1000  0.652174  0.383345   0.786462  0.384364\n",
      "5      P2_bgd_sigmoid_1_0.1_32_1000  0.643478  0.379609   0.775665  0.385591\n",
      "6    P2_sgd_sigmoid_1_0.001_32_1000  0.643478  0.359126   0.797527  0.354864\n",
      "7        P2_sgd_tanh_1_0.01_32_1000  0.626087  0.297461   0.758027  0.316136\n",
      "8        P2_bgd_tanh_1_0.01_32_1000  0.617391  0.358322   0.748457  0.372500\n",
      "9       P2_mbgd_tanh_1_0.01_32_1000  0.617391  0.305187   0.775000  0.314636\n",
      "10   P2_mbgd_sigmoid_1_0.01_32_1000  0.608696  0.305519   0.839297  0.312273\n",
      "11      P2_mbgd_tanh_1_0.01_64_1000  0.600000  0.465156   0.643001  0.291818\n",
      "12       P2_mbgd_tanh_1_0.1_32_1000  0.600000  0.358617   0.788425  0.349682\n",
      "13     P2_sgd_sigmoid_1_0.1_32_1000  0.600000  0.351659   0.759146  0.350773\n",
      "14  P2_mbgd_sigmoid_1_0.001_64_1000  0.600000  0.263000   0.839685  0.291818\n",
      "15      P2_sgd_relu_1_0.001_32_1000  0.600000  0.233194   0.724120  0.409848\n",
      "16    P2_mbgd_sigmoid_1_0.1_32_1000  0.591304  0.345169   0.741309  0.351455\n",
      "17  P2_mbgd_sigmoid_1_0.001_32_1000  0.582609  0.317435   0.761875  0.315091\n",
      "18       P2_mbgd_tanh_1_0.1_64_1000  0.582609  0.291705   0.693187  0.301364\n",
      "19        P2_sgd_tanh_1_0.1_32_1000  0.573913  0.273701   0.847436  0.293227\n",
      "20   P2_bgd_sigmoid_1_0.001_32_1000  0.556522  0.244383   0.822868  0.271273\n",
      "21     P2_mbgd_tanh_1_0.001_32_1000  0.539130  0.197423   0.680205  0.385152\n",
      "22      P2_bgd_tanh_1_0.001_32_1000  0.530435  0.232802   0.812462  0.258182\n",
      "23     P2_mbgd_tanh_1_0.001_64_1000  0.521739  0.360518   0.513017  0.377121\n",
      "24      P2_mbgd_relu_1_0.01_64_1000  0.495652  0.355018   0.543750  0.373485\n",
      "25      P2_mbgd_relu_1_0.01_32_1000  0.486957  0.527579   0.358907  0.363333\n",
      "26        P2_bgd_tanh_1_0.1_32_1000  0.434783  0.164777   0.461966  0.450455\n",
      "27      P2_bgd_relu_1_0.001_32_1000  0.391304  0.174962   0.715201  0.323485\n",
      "28     P2_mbgd_relu_1_0.001_32_1000  0.347826  0.131854   0.592262  0.403506\n",
      "29     P2_mbgd_relu_1_0.001_64_1000  0.295652  0.262800   0.403409  0.502500\n",
      "30       P2_mbgd_relu_1_0.1_32_1000  0.243478  0.118333   0.639818  0.274167\n",
      "31       P2_sgd_relu_1_0.01_32_1000  0.000000  0.166667   0.666667  0.166667\n",
      "32       P2_bgd_relu_1_0.01_32_1000  0.000000  0.000000   0.833333  0.166667\n",
      "33        P2_bgd_relu_1_0.1_32_1000  0.000000  0.000000   0.833333  0.166667\n",
      "34        P2_sgd_relu_1_0.1_32_1000  0.000000  0.000000   0.833333  0.166667\n",
      "35       P2_mbgd_relu_1_0.1_64_1000  0.000000  0.000000   0.714286  0.285714\n"
     ]
    }
   ],
   "source": [
    "columns = [\"Name\", \"accuracy\", \"f1\", \"precision\", \"recall\"]\n",
    "print(wandb_data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Learning Rate=%{x}<br>Activation Function=%{y}<br>Optimizer=%{z}<br>Accuracy=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0.6782608695652174,
           0.6782608695652174,
           0.6695652173913044,
           0.6521739130434783,
           0.6521739130434783,
           0.6434782608695652,
           0.6434782608695652,
           0.6260869565217392,
           0.6173913043478261,
           0.6173913043478261,
           0.6086956521739131,
           0.6,
           0.6,
           0.6,
           0.6,
           0.6,
           0.591304347826087,
           0.5826086956521739,
           0.5826086956521739,
           0.5739130434782609,
           0.5565217391304348,
           0.5391304347826087,
           0.5304347826086957,
           0.5217391304347826,
           0.4956521739130435,
           0.4869565217391304,
           0.4347826086956521,
           0.391304347826087,
           0.3478260869565217,
           0.2956521739130435,
           0.2434782608695652,
           0,
           0,
           0,
           0,
           0
          ],
          "coloraxis": "coloraxis",
          "size": [
           0.6782608695652174,
           0.6782608695652174,
           0.6695652173913044,
           0.6521739130434783,
           0.6521739130434783,
           0.6434782608695652,
           0.6434782608695652,
           0.6260869565217392,
           0.6173913043478261,
           0.6173913043478261,
           0.6086956521739131,
           0.6,
           0.6,
           0.6,
           0.6,
           0.6,
           0.591304347826087,
           0.5826086956521739,
           0.5826086956521739,
           0.5739130434782609,
           0.5565217391304348,
           0.5391304347826087,
           0.5304347826086957,
           0.5217391304347826,
           0.4956521739130435,
           0.4869565217391304,
           0.4347826086956521,
           0.391304347826087,
           0.3478260869565217,
           0.2956521739130435,
           0.2434782608695652,
           0,
           0,
           0,
           0,
           0
          ],
          "sizemode": "area",
          "sizeref": 0.0016956521739130434,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "scene": "scene",
         "showlegend": false,
         "type": "scatter3d",
         "x": [
          0.01,
          0.001,
          0.01,
          0.01,
          0.1,
          0.1,
          0.001,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.1,
          0.1,
          0.001,
          0.001,
          0.1,
          0.001,
          0.1,
          0.1,
          0.001,
          0.001,
          0.001,
          0.001,
          0.01,
          0.01,
          0.1,
          0.001,
          0.001,
          0.001,
          0.1,
          0.01,
          0.01,
          0.1,
          0.1,
          0.1
         ],
         "y": [
          "sigmoid",
          "tanh",
          "sigmoid",
          "sigmoid",
          "sigmoid",
          "sigmoid",
          "sigmoid",
          "tanh",
          "tanh",
          "tanh",
          "sigmoid",
          "tanh",
          "tanh",
          "sigmoid",
          "sigmoid",
          "relu",
          "sigmoid",
          "sigmoid",
          "tanh",
          "tanh",
          "sigmoid",
          "tanh",
          "tanh",
          "tanh",
          "relu",
          "relu",
          "tanh",
          "relu",
          "relu",
          "relu",
          "relu",
          "relu",
          "relu",
          "relu",
          "relu",
          "relu"
         ],
         "z": [
          "sgd",
          "sgd",
          "mbgd",
          "bgd",
          "mbgd",
          "bgd",
          "sgd",
          "sgd",
          "bgd",
          "mbgd",
          "mbgd",
          "mbgd",
          "mbgd",
          "sgd",
          "mbgd",
          "sgd",
          "mbgd",
          "mbgd",
          "mbgd",
          "sgd",
          "bgd",
          "mbgd",
          "bgd",
          "mbgd",
          "mbgd",
          "mbgd",
          "bgd",
          "bgd",
          "mbgd",
          "mbgd",
          "mbgd",
          "sgd",
          "bgd",
          "bgd",
          "sgd",
          "mbgd"
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Accuracy"
          }
         },
         "colorscale": [
          [
           0,
           "#fde725"
          ],
          [
           0.1111111111111111,
           "#b5de2b"
          ],
          [
           0.2222222222222222,
           "#6ece58"
          ],
          [
           0.3333333333333333,
           "#35b779"
          ],
          [
           0.4444444444444444,
           "#1f9e89"
          ],
          [
           0.5555555555555556,
           "#26828e"
          ],
          [
           0.6666666666666666,
           "#31688e"
          ],
          [
           0.7777777777777778,
           "#3e4989"
          ],
          [
           0.8888888888888888,
           "#482878"
          ],
          [
           1,
           "#440154"
          ]
         ]
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "Learning Rate"
          }
         },
         "yaxis": {
          "title": {
           "text": "Activation Function"
          }
         },
         "zaxis": {
          "title": {
           "text": "Optimizer"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Scatter Plot with Inversely Colored Accuracy"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter_3d(wandb_data, x='lr', y='activation', z='optimizer', color='accuracy', size='accuracy',\n",
    "                    color_continuous_scale='Viridis_r', labels={'lr': 'Learning Rate', 'activation': 'Activation Function', 'optimizer': 'Optimizer', 'accuracy': 'Accuracy'},\n",
    "                    title='3D Scatter Plot with Inversely Colored Accuracy')\n",
    "\n",
    "fig.update_traces(marker=dict(size=12, opacity=0.8),\n",
    "                  selector=dict(mode='markers+text'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params = ['sgd', 'sigmoid', 1, 0.01, 32, 1000] # optimizer, activation, hidden_layers, lr, batch_size, max_epochs\n",
    "# Taken from hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.70      0.80      0.75        50\n",
      "           6       0.56      0.64      0.60        44\n",
      "           7       0.62      0.31      0.42        16\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.63       115\n",
      "   macro avg       0.38      0.35      0.35       115\n",
      "weighted avg       0.61      0.63      0.61       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = MLP_Classifier(X_train_std.shape[1], hidden_layers, num_classes, learning_rate=best_model_params[3], activation=best_model_params[1], optimizer=best_model_params[0], print_every=None)\n",
    "best_model.train(X_train_std, y_train, max_epochs=best_model_params[5], batch_size=best_model_params[4], X_validation=X_validation_std, y_validation=y_validation)\n",
    "\n",
    "print(classification_report(y_test, best_model.predict(X_test_std), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "\n",
    "![Alt text](../P1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we can see that the accuracy for the MLP model > Logistic Regression model. So, we can say that MLP model is the best model for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
