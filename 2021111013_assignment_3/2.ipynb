{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../Datasets/WineQT.csv\"\n",
    "\n",
    "random_state = 42\n",
    "wandb_log = True\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "hyperparameter_tuning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "max_epochs = 10000\n",
    "optimizer = 'bgd'\n",
    "activation = 'sigmoid'\n",
    "hidden_layers = [8,]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_init(lr, max_epochs, optimizer, activation, hidden_layers, batch_size):\n",
    "    if wandb_log:\n",
    "        config = {\n",
    "            \"lr\": lr, \n",
    "            \"model_type\": \"MLP_Classifier\",\n",
    "            \"optimizer\": optimizer, # SGC/BGD/MBGD\n",
    "            \"criterion\": \"mse\",\n",
    "            \"num_epochs\": max_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"hidden_layers\": hidden_layers,\n",
    "            \"activation\": activation,\n",
    "            # \"gpu_id\": 0,\n",
    "            \"wandb_run_name\": \"bhav\" ,\n",
    "            \"tags\": [\"P2\",]\n",
    "        }\n",
    "\n",
    "        wandb.init(entity = \"bhavberi\",   # wandb username. (NOT REQUIRED ARG. ANYMORE, it fetches from initial login)\n",
    "                project = \"SMAI\",        # wandb project name. New project will be created if given project is missing.\n",
    "                config = config         # Config dict\n",
    "                )\n",
    "        wandb.run.name = f\"P2_{config['optimizer']}_{config['activation']}_{len(config['hidden_layers'])}_{config['lr']}_{config['batch_size']}_{config['num_epochs']}\"\n",
    "        print(wandb.run.name)\n",
    "\n",
    "def wandb_finish():\n",
    "    if wandb_log:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality', 'Id'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(dataset_path)\n",
    "print(dataset.columns)\n",
    "dataset.drop(['Id'], axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.311111</td>\n",
       "      <td>0.531339</td>\n",
       "      <td>0.268364</td>\n",
       "      <td>2.532152</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>15.615486</td>\n",
       "      <td>45.914698</td>\n",
       "      <td>0.996730</td>\n",
       "      <td>3.311015</td>\n",
       "      <td>0.657708</td>\n",
       "      <td>10.442111</td>\n",
       "      <td>5.657043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.747595</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.196686</td>\n",
       "      <td>1.355917</td>\n",
       "      <td>0.047267</td>\n",
       "      <td>10.250486</td>\n",
       "      <td>32.782130</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.156664</td>\n",
       "      <td>0.170399</td>\n",
       "      <td>1.082196</td>\n",
       "      <td>0.805824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.995570</td>\n",
       "      <td>3.205000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.996680</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.997845</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1143.000000       1143.000000  1143.000000     1143.000000   \n",
       "mean        8.311111          0.531339     0.268364        2.532152   \n",
       "std         1.747595          0.179633     0.196686        1.355917   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.392500     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.250000        2.200000   \n",
       "75%         9.100000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1143.000000          1143.000000           1143.000000  1143.000000   \n",
       "mean      0.086933            15.615486             45.914698     0.996730   \n",
       "std       0.047267            10.250486             32.782130     0.001925   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             21.000000     0.995570   \n",
       "50%       0.079000            13.000000             37.000000     0.996680   \n",
       "75%       0.090000            21.000000             61.000000     0.997845   \n",
       "max       0.611000            68.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1143.000000  1143.000000  1143.000000  1143.000000  \n",
       "mean      3.311015     0.657708    10.442111     5.657043  \n",
       "std       0.156664     0.170399     1.082196     0.805824  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.205000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['quality']).to_numpy()\n",
    "y = dataset['quality'].to_numpy()\n",
    "\n",
    "num_classes = 11 # 0-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "# To fill in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (914, 11) (914,)\n",
      "Validation set shape: (114, 11) (114,)\n",
      "Test set shape: (115, 11) (115,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_state)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_validation.shape, y_validation.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_validation_std = scaler.transform(X_validation)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Classifier:\n",
    "    def __init__(self, input_size, hidden_layers, num_classes=11, learning_rate=0.01, activation='sigmoid', optimizer='sgd', wandb_log=False, print_every=10):\n",
    "        assert activation.lower() in ['sigmoid', 'relu', 'tanh'], \"Activation function must be either 'sigmoid', 'relu' or 'tanh'\"\n",
    "        assert optimizer.lower() in ['sgd', 'bgd', 'mbgd'], \"Optimizer must be either 'sgd', 'bgd' or 'mbgd'\"\n",
    "        assert input_size > 0, \"Input size must be greater than 0\"\n",
    "        assert num_classes > 0, \"Output size must be greater than 0\"\n",
    "        assert learning_rate > 0, \"Learning rate must be greater than 0\"\n",
    "        assert type(hidden_layers) == list and len(hidden_layers) > 0, \"Hidden layers must be a list of size greater than 0\"\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        self.activation_func = self._get_activation_func(activation)\n",
    "        self.optimizer_func = self._get_optimizer_func(optimizer)\n",
    "        self.weights, self.biases = self._initialize_weights_and_biases()\n",
    "\n",
    "        self.wandb_log = wandb_log\n",
    "        self.print_every = print_every\n",
    "    \n",
    "    # Activation functions\n",
    "    def _get_activation_func(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            return self._sigmoid\n",
    "        elif activation == 'tanh':\n",
    "            return self._tanh\n",
    "        elif activation == 'relu':\n",
    "            return self._relu\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function '{activation}' not supported.\")\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    # Activation derivative\n",
    "    def _activation_derivative(self, Z):\n",
    "        if self.activation_func == self._sigmoid:\n",
    "            return self._sigmoid_derivative(Z)\n",
    "        elif self.activation_func == self._tanh:\n",
    "            return self._tanh_derivative(Z)\n",
    "        elif self.activation_func == self._relu:\n",
    "            return self._relu_derivative(Z)\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function '{self.activation_func}' not supported.\")\n",
    "    \n",
    "    def _sigmoid_derivative(self, Z):\n",
    "        return self._sigmoid(Z) * (1 - self._sigmoid(Z))\n",
    "    \n",
    "    def _tanh_derivative(self, Z):\n",
    "        return 1 - np.square(self._tanh(Z))\n",
    "    \n",
    "    def _relu_derivative(self, Z):\n",
    "        return np.where(Z > 0, 1, 0)\n",
    "    \n",
    "    ## Optimizers\n",
    "    def _get_optimizer_func(self, optimizer):\n",
    "        if optimizer == 'sgd':\n",
    "            return self._sgd\n",
    "        elif optimizer == 'bgd':\n",
    "            return self._bgd\n",
    "        elif optimizer == 'mbgd':\n",
    "            return self._mbgd\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer '{optimizer}' not supported.\")\n",
    "    \n",
    "    def _sgd(self, grads):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= (self.learning_rate * grads['dW'][i])\n",
    "            self.biases[i] -= (self.learning_rate * grads['db'][i])\n",
    "    \n",
    "    def _bgd(self, grads):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= (self.learning_rate * grads['dW'][i] / self.input_size)\n",
    "            self.biases[i] -= (self.learning_rate * grads['db'][i] / self.input_size)\n",
    "\n",
    "    def _mbgd(self, grads):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= (self.learning_rate * grads['dW'][i] / grads['dW'][i].shape[1])\n",
    "            self.biases[i] -= (self.learning_rate * grads['db'][i] / grads['db'][i].shape[1])\n",
    "    \n",
    "    # Initialize weights and biases\n",
    "    def _initialize_weights_and_biases(self):\n",
    "        num_layers = len(self.hidden_layers)\n",
    "        weights = []\n",
    "        biases = []\n",
    "\n",
    "        if num_layers == 0:\n",
    "            w = np.random.randn(self.input_size, self.output_size)\n",
    "            b = np.zeros((1, self.output_size))\n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "            return weights, biases\n",
    "        \n",
    "        # Using Github Copilot\n",
    "        for i in range(num_layers + 1):\n",
    "            if i == 0:\n",
    "                w = np.random.randn(self.input_size, self.hidden_layers[0])\n",
    "            elif i == num_layers:\n",
    "                w = np.random.randn(self.hidden_layers[-1], self.output_size)\n",
    "            else:\n",
    "                w = np.random.randn(self.hidden_layers[i - 1], self.hidden_layers[i])\n",
    "            \n",
    "            b = np.zeros((1, w.shape[1]))\n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "    \n",
    "    # Forward propagation\n",
    "    def _forward_propagation(self, X):\n",
    "        num_layers = len(self.weights)\n",
    "        A = X\n",
    "        caches = []\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            W = self.weights[i]\n",
    "            b = self.biases[i]\n",
    "            Z = np.dot(A, W) + b\n",
    "            \n",
    "            if Z.shape[1] == 1:\n",
    "                Z = Z.reshape(-1)\n",
    "            caches.append((A, W, b, Z))\n",
    "            # print(A.shape, W.shape, b.shape, Z.shape)\n",
    "\n",
    "            A = self.activation_func(Z)\n",
    "        \n",
    "        if len(A.shape) == 1:\n",
    "            A = A.reshape(-1)\n",
    "        return A, caches\n",
    "\n",
    "    # Backward propagation\n",
    "    def _backward_propagation(self, A, Y, caches):\n",
    "        num_samples = A.shape[0]\n",
    "        num_layers = len(self.weights)\n",
    "        grads = {'dW': [], 'db': []}\n",
    "\n",
    "        delta = A-Y\n",
    "        # print(delta.shape, A.shape, Y.shape)\n",
    "\n",
    "        for i in reversed(range(num_layers)):\n",
    "            A, W, _, Z = caches[i]\n",
    "            # print(\"A\", A.shape, \"W\", W.shape, \"Z\", Z.shape)\n",
    "            \n",
    "            dZ = np.multiply(delta, self._activation_derivative(Z))\n",
    "            if dZ.ndim == 1:\n",
    "                dZ = dZ.reshape((dZ.shape[0], 1))\n",
    "            # print(\"dZ\", dZ.shape)\n",
    "            dW = np.dot(A.T, dZ)\n",
    "            # print(\"dW\", dW.shape)\n",
    "            db = np.sum(dZ, axis=0, keepdims=True)\n",
    "            # print(\"db\", db.shape)\n",
    "\n",
    "            delta = np.dot(dZ, W.T)\n",
    "            # print(\"delta\", delta.shape)\n",
    "\n",
    "            if len(dW.shape) == 1:\n",
    "                dW = dW.reshape(-1, 1)\n",
    "\n",
    "            grads['dW'].append(dW)\n",
    "            grads['db'].append(db)\n",
    "        \n",
    "        grads['dW'].reverse()\n",
    "        grads['db'].reverse()\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    # Calculate cost\n",
    "    def _calculate_cost(self, A, Y):\n",
    "        cost = np.mean(np.not_equal(A, Y))\n",
    "        return cost\n",
    "\n",
    "    # Predict\n",
    "    def predict(self, X):\n",
    "        A, _ = self._forward_propagation(X)\n",
    "\n",
    "        # Apply a softmax to get probabilities & then getting the h9ghest probability\n",
    "        A = np.exp(A) / np.sum(np.exp(A), axis=1, keepdims=True)\n",
    "\n",
    "        A = np.argmax(A,axis=1)\n",
    "        return A\n",
    "\n",
    "    # Train the model\n",
    "    def train(self, X, Y, max_epochs=10, batch_size=32, X_validation=None, y_validation=None):\n",
    "        num_samples = X.shape[0]\n",
    "        costs = []\n",
    "\n",
    "        enc = OneHotEncoder().fit(np.array([[i,] for i in range(num_classes)]))\n",
    "        y_new = enc.transform(Y.reshape(-1, 1)).toarray()\n",
    "        \n",
    "        for i in range(max_epochs):\n",
    "            if self.optimizer == \"bgd\":\n",
    "                batch_size = num_samples\n",
    "                num_batches = 1\n",
    "            elif self.optimizer == \"sgd\":\n",
    "                batch_size = 1\n",
    "                num_batches = num_samples\n",
    "            elif self.optimizer == \"mbgd\":\n",
    "                num_batches = num_samples // batch_size\n",
    "            else:\n",
    "                raise ValueError(f\"Optimizer '{self.optimizer}' not supported.\")\n",
    "\n",
    "            for j in range(num_batches):\n",
    "                start = j * batch_size\n",
    "                end = start + batch_size\n",
    "                \n",
    "                A, caches = self._forward_propagation(X[start:end])\n",
    "                grads = self._backward_propagation(A, y_new[start:end], caches)\n",
    "                self.optimizer_func(grads)\n",
    "            \n",
    "            A = self.predict(X)\n",
    "            cost = self._calculate_cost(A, Y)\n",
    "            costs.append(cost)\n",
    "\n",
    "            data_to_log = {\n",
    "                \"epoch\": i + 1,\n",
    "                \"train_loss\": cost\n",
    "            }\n",
    "\n",
    "            # Calculate validation loss\n",
    "            if X_validation is not None and y_validation is not None:\n",
    "                A = self.predict(X_validation)\n",
    "                val_loss = self._calculate_cost(A, y_validation)\n",
    "                data_to_log[\"val_loss\"] = val_loss\n",
    "\n",
    "            if self.wandb_log:\n",
    "                wandb.log(data_to_log)\n",
    "            \n",
    "            if self.print_every and (i+1) % self.print_every == 0:\n",
    "                print(f\"Cost after {i+1} epochs: {cost}\")\n",
    "        \n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 100 epochs: 0.8665207877461707\n",
      "Cost after 200 epochs: 0.6673960612691466\n",
      "Cost after 300 epochs: 0.5087527352297593\n",
      "Cost after 400 epochs: 0.4671772428884026\n",
      "Cost after 500 epochs: 0.4540481400437637\n",
      "Cost after 600 epochs: 0.4474835886214442\n",
      "Cost after 700 epochs: 0.44091903719912473\n",
      "Cost after 800 epochs: 0.437636761487965\n",
      "Cost after 900 epochs: 0.4288840262582057\n",
      "Cost after 1000 epochs: 0.42669584245076586\n",
      "Cost after 1100 epochs: 0.4201312910284464\n",
      "Cost after 1200 epochs: 0.4223194748358862\n",
      "Cost after 1300 epochs: 0.4223194748358862\n",
      "Cost after 1400 epochs: 0.4223194748358862\n",
      "Cost after 1500 epochs: 0.4212253829321663\n",
      "Cost after 1600 epochs: 0.4223194748358862\n",
      "Cost after 1700 epochs: 0.424507658643326\n",
      "Cost after 1800 epochs: 0.424507658643326\n",
      "Cost after 1900 epochs: 0.42560175054704596\n",
      "Cost after 2000 epochs: 0.4201312910284464\n",
      "Cost after 2100 epochs: 0.4179431072210066\n",
      "Cost after 2200 epochs: 0.4190371991247265\n",
      "Cost after 2300 epochs: 0.4201312910284464\n",
      "Cost after 2400 epochs: 0.41575492341356673\n",
      "Cost after 2500 epochs: 0.4135667396061269\n",
      "Cost after 2600 epochs: 0.4135667396061269\n",
      "Cost after 2700 epochs: 0.4135667396061269\n",
      "Cost after 2800 epochs: 0.412472647702407\n",
      "Cost after 2900 epochs: 0.4102844638949672\n",
      "Cost after 3000 epochs: 0.4102844638949672\n",
      "Cost after 3100 epochs: 0.4102844638949672\n",
      "Cost after 3200 epochs: 0.40919037199124725\n",
      "Cost after 3300 epochs: 0.40809628008752735\n",
      "Cost after 3400 epochs: 0.40809628008752735\n",
      "Cost after 3500 epochs: 0.40700218818380746\n",
      "Cost after 3600 epochs: 0.4048140043763676\n",
      "Cost after 3700 epochs: 0.4048140043763676\n",
      "Cost after 3800 epochs: 0.4059080962800875\n",
      "Cost after 3900 epochs: 0.4059080962800875\n",
      "Cost after 4000 epochs: 0.40809628008752735\n",
      "Cost after 4100 epochs: 0.40700218818380746\n",
      "Cost after 4200 epochs: 0.4059080962800875\n",
      "Cost after 4300 epochs: 0.4037199124726477\n",
      "Cost after 4400 epochs: 0.40043763676148797\n",
      "Cost after 4500 epochs: 0.40043763676148797\n",
      "Cost after 4600 epochs: 0.40043763676148797\n",
      "Cost after 4700 epochs: 0.3993435448577681\n",
      "Cost after 4800 epochs: 0.3993435448577681\n",
      "Cost after 4900 epochs: 0.3993435448577681\n",
      "Cost after 5000 epochs: 0.3993435448577681\n",
      "Cost after 5100 epochs: 0.3993435448577681\n",
      "Cost after 5200 epochs: 0.3993435448577681\n",
      "Cost after 5300 epochs: 0.3993435448577681\n",
      "Cost after 5400 epochs: 0.3982494529540481\n",
      "Cost after 5500 epochs: 0.3982494529540481\n",
      "Cost after 5600 epochs: 0.3993435448577681\n",
      "Cost after 5700 epochs: 0.3993435448577681\n",
      "Cost after 5800 epochs: 0.3982494529540481\n",
      "Cost after 5900 epochs: 0.3982494529540481\n",
      "Cost after 6000 epochs: 0.39606126914660833\n",
      "Cost after 6100 epochs: 0.39606126914660833\n",
      "Cost after 6200 epochs: 0.3949671772428884\n",
      "Cost after 6300 epochs: 0.3949671772428884\n",
      "Cost after 6400 epochs: 0.3949671772428884\n",
      "Cost after 6500 epochs: 0.3927789934354486\n",
      "Cost after 6600 epochs: 0.3927789934354486\n",
      "Cost after 6700 epochs: 0.3916849015317287\n",
      "Cost after 6800 epochs: 0.39059080962800874\n",
      "Cost after 6900 epochs: 0.38949671772428884\n",
      "Cost after 7000 epochs: 0.3916849015317287\n",
      "Cost after 7100 epochs: 0.3916849015317287\n",
      "Cost after 7200 epochs: 0.3916849015317287\n",
      "Cost after 7300 epochs: 0.39059080962800874\n",
      "Cost after 7400 epochs: 0.38949671772428884\n",
      "Cost after 7500 epochs: 0.38949671772428884\n",
      "Cost after 7600 epochs: 0.3862144420131291\n",
      "Cost after 7700 epochs: 0.38293216630196936\n",
      "Cost after 7800 epochs: 0.38293216630196936\n",
      "Cost after 7900 epochs: 0.38402625820568925\n",
      "Cost after 8000 epochs: 0.38293216630196936\n",
      "Cost after 8100 epochs: 0.38183807439824946\n",
      "Cost after 8200 epochs: 0.38183807439824946\n",
      "Cost after 8300 epochs: 0.38293216630196936\n",
      "Cost after 8400 epochs: 0.38402625820568925\n",
      "Cost after 8500 epochs: 0.3851203501094092\n",
      "Cost after 8600 epochs: 0.3851203501094092\n",
      "Cost after 8700 epochs: 0.3851203501094092\n",
      "Cost after 8800 epochs: 0.3851203501094092\n",
      "Cost after 8900 epochs: 0.38402625820568925\n",
      "Cost after 9000 epochs: 0.38402625820568925\n",
      "Cost after 9100 epochs: 0.38293216630196936\n",
      "Cost after 9200 epochs: 0.38074398249452956\n",
      "Cost after 9300 epochs: 0.38074398249452956\n",
      "Cost after 9400 epochs: 0.38183807439824946\n",
      "Cost after 9500 epochs: 0.38074398249452956\n",
      "Cost after 9600 epochs: 0.3796498905908096\n",
      "Cost after 9700 epochs: 0.3796498905908096\n",
      "Cost after 9800 epochs: 0.38074398249452956\n",
      "Cost after 9900 epochs: 0.38074398249452956\n",
      "Cost after 10000 epochs: 0.38074398249452956\n"
     ]
    }
   ],
   "source": [
    "model = MLP_Classifier(X_train_std.shape[1], hidden_layers, num_classes, learning_rate=lr, activation=activation, optimizer=optimizer, print_every=100)\n",
    "costs = model.train(X_train_std, y_train, max_epochs=max_epochs, batch_size=batch_size, X_validation=X_validation_std, y_validation=y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(costs)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.69      0.82      0.75        50\n",
      "           6       0.56      0.66      0.60        44\n",
      "           7       1.00      0.25      0.40        16\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.64       115\n",
      "   macro avg       0.45      0.35      0.35       115\n",
      "weighted avg       0.65      0.64      0.61       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test_std), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparameter_tuning:\n",
    "    for optimizer in ['sgd', 'bgd', 'mbgd']:\n",
    "        for activation in ['sigmoid', 'relu', 'tanh']:\n",
    "            for lr in [0.001, 0.01, 0.1]:\n",
    "                max_epochs = 1000\n",
    "                if optimizer == 'mbgd':\n",
    "                    batch_sizes = [32, 64]\n",
    "                else:\n",
    "                    batch_sizes = [32,]\n",
    "                for batch_size in batch_sizes:\n",
    "                    wandb_init(lr, max_epochs, optimizer, activation, hidden_layers, batch_size)\n",
    "                    model = MLP_Classifier(X_train_std.shape[1], hidden_layers, num_classes, learning_rate=lr, activation=activation, optimizer=optimizer, print_every=None, wandb_log=wandb_log)\n",
    "                    costs = model.train(X_train_std, y_train, max_epochs=max_epochs, batch_size=batch_size, X_validation=X_validation_std, y_validation=y_validation)\n",
    "                    accuracy = accuracy_score(y_test, model.predict(X_test_std))\n",
    "                    precision = precision_score(y_test, model.predict(X_test_std), average='macro', zero_division=1)\n",
    "                    recall = recall_score(y_test, model.predict(X_test_std), average='macro', zero_division=1)\n",
    "                    f1 = f1_score(y_test, model.predict(X_test_std), average='macro', zero_division=1)\n",
    "                    if wandb_log:\n",
    "                        wandb.log({\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"precision\": precision,\n",
    "                            \"recall\": recall,\n",
    "                            \"f1\": f1\n",
    "                        })\n",
    "                    wandb_finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
